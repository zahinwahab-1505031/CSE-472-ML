538702.5, 539192.5, 539713.5, 540288.0, 540997.0, 541312.5, 541540.0, 542001.0, 542646.5, 543035.0, 543102.0, 543319.5, 543699.5, 544006.5, 544179.5, 544477.0, 544739.0, 545137.5, 546684.5, 548071.0, 548279.5, 548332.0, 548435.5, 548545.0, 548622.0, 548919.0, 549257.5, 549345.0, 549381.0, 549421.5, 550139.0, 551405.0, 552158.0, 552879.5, 553439.0, 553839.5, 554261.5, 554651.5, 555819.0, 556656.0, 556674.0, 556795.0, 556992.0, 557159.0, 557292.5, 557496.5, 557748.5, 558018.0, 558336.5, 558717.0, 559874.0, 561069.0, 561411.5, 561912.5, 562447.0, 563220.5, 564009.0, 564724.0, 565681.0, 566083.0, 566327.0, 567162.5, 568139.0, 569125.5, 569845.5, 569966.0, 570282.0, 570691.5, 570919.0, 571435.0, 572302.0, 573167.0, 573794.0, 574138.0, 574856.5, 576481.5, 577949.0, 578539.0, 579474.5, 580659.5, 582413.0, 584007.0, 584524.5, 584996.5, 585282.0, 586009.0, 586983.5, 587656.5, 588243.5, 588694.5, 589357.0, 590760.0, 592320.5, 593088.0, 593716.5, 594593.5, 595044.0, 595274.5, 596118.5, 597309.5, 598224.5, 598704.0, 598898.5, 599312.0, 601071.0, 603279.0, 604212.5, 604443.0, 604521.5, 605019.5, 605806.5, 606431.5, 607275.5, 607823.5, 608016.0, 608986.5, 609862.0, 610482.0, 613198.0, 615630.0, 616457.0, 
617440.5, 617879.0, 618044.5, 623494.0, 630372.0, 632270.0, 632603.0, 632723.5, 633288.0, 633984.0, 635069.5, 635965.0, 636548.5, 637151.0, 638802.5, 641606.5, 645356.0, 648052.5, 649809.5, 652485.0, 653857.5, 655088.5, 656716.5, 658335.0, 659388.5, 659531.0, 660009.5, 660665.5, 662132.0, 663880.0, 664518.0, 664745.5, 666570.0, 668340.5, 669827.0, 671852.0, 673088.0, 674592.5, 677905.5, 681668.5, 683481.0, 686185.0, 690092.5, 691866.5, 692484.5, 693939.0, 694974.0, 695273.5, 696887.0, 698390.5, 700742.5, 703087.0, 703607.5, 705067.0, 706103.0, 707812.5, 709621.5, 712868.0, 716002.0, 716241.0, 718788.5, 721436.5, 726907.0, 732335.5, 733381.0, 735754.0, 738063.5, 742290.0, 745792.5, 746124.5, 746609.0, 747252.5, 748412.0, 749370.5, 750304.0, 753415.0, 757279.0, 759853.0, 763560.5, 766759.0, 779243.5, 793457.0, 797555.5, 802798.5, 806434.0, 808068.5, 813167.5, 833303.5, 853694.5, 858940.0, 875156.5, 900181.5, 911922.5, 915333.5, 924084.0, 942268.0, 962971.0, 976991.0, 1007425.0, 1035887.5, 1062034.0, 1091484.0, 1111533.0, 1143488.0, 1172992.5, 1205602.5, 1247461.0, 1317229.5, 1410777.5, 1470070.0, 1499340.0]
FINAL SPLIT:  209923.0
capital-gain
119
=================================================================================
120
[-57.0, 57.0, 257.5, 497.5, 754.0, 952.5, 1023.0, 1070.5, 1098.5, 1131.0, 1162.0, 1291.0, 1416.5, 1439.5, 1463.0, 1488.5, 1572.5, 1718.0, 1814.0, 1839.5, 1928.5, 2022.5, 2043.0, 2056.0, 2083.5, 2139.5, 2175.0, 2189.0, 2215.0, 2259.0, 2309.5, 
2337.5, 2350.0, 2370.5, 2397.0, 2410.5, 2438.5, 2500.5, 2559.0, 2588.5, 2616.0, 2644.0, 2741.0, 2857.0, 2896.0, 2921.5, 2948.5, 2962.5, 2970.5, 2985.0, 3048.0, 3120.0, 3205.0, 3299.0, 3368.0, 3414.5, 3425.0, 3444.0, 3460.0, 3467.5, 3572.5, 3727.5, 3799.5, 3852.5, 3897.5, 3925.0, 4003.0, 4082.5, 4243.5, 4401.0, 4462.0, 4579.0, 4668.5, 4737.0, 4826.0, 4898.0, 4932.5, 4973.5, 5036.5, 5119.0, 5316.5, 5505.5, 5638.5, 5909.0, 6228.5, 6389.0, 6457.5, 6505.5, 6618.5, 6745.0, 6808.0, 7073.5, 7364.0, 7436.5, 7565.5, 7792.0, 7937.0, 8296.0, 9000.0, 9474.0, 10041.0, 10543.0, 10585.5, 11141.5, 12614.0, 13817.0, 14214.0, 14682.0, 15022.0, 15427.5, 17156.0, 19266.0, 21045.5, 23582.0, 25180.0, 26532.0, 30961.5, 37702.5, 70654.5, 129343.5]
FINAL SPLIT:  7073.5
capital-loss
92
=================================================================================
93
[-77.5, 77.5, 184.0, 268.0, 371.0, 522.0, 639.0, 731.5, 845.0, 927.0, 1033.0, 1115.0, 1198.0, 1299.0, 1360.0, 1394.0, 1409.5, 1448.0, 1494.5, 1521.5, 1551.5, 1568.5, 1576.0, 1584.5, 1592.0, 1598.0, 1609.5, 1622.5, 1638.0, 1649.5, 1659.5, 1668.5, 1670.5, 1695.5, 1720.0, 1723.5, 1730.5, 1737.5, 1740.5, 1748.0, 1758.5, 1789.0, 1820.5, 1834.5, 1846.0, 1862.0, 1881.5, 1894.5, 1923.0, 1959.0, 1975.5, 1978.5, 1990.5, 2001.5, 2022.0, 2046.5, 2054.0, 2068.5, 2104.5, 2139.0, 2156.0, 2168.5, 2176.5, 2190.0, 2203.0, 2205.5, 2218.5, 2234.5, 2242.0, 2252.0, 2262.5, 2274.5, 2310.5, 2345.5, 2364.5, 2384.5, 2403.5, 2429.5, 2450.5, 2462.0, 2469.5, 2480.5, 2518.0, 2553.0, 2581.0, 2678.5, 2789.0, 2914.0, 3343.5, 3726.5, 3835.0, 4128.0, 
4584.0]
FINAL SPLIT:  1820.5
hours-per-week
94
95
[0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5, 11.5, 12.5, 13.5, 14.5, 15.5, 16.5, 17.5, 18.5, 19.5, 20.5, 21.5, 22.5, 23.5, 24.5, 25.5, 26.5, 27.5, 28.5, 29.5, 30.5, 31.5, 32.5, 33.5, 34.5, 35.5, 36.5, 37.5, 38.5, 39.5, 40.5, 41.5, 42.5, 43.5, 44.5, 45.5, 46.5, 47.5, 48.5, 49.5, 50.5, 51.5, 52.5, 53.5, 54.5, 55.5, 56.5, 57.5, 58.5, 59.5, 60.5, 61.5, 
62.5, 63.5, 64.5, 65.5, 66.5, 67.5, 69.0, 71.0, 72.5, 73.5, 74.5, 75.5, 76.5, 77.5, 79.0, 80.5, 81.5, 83.0, 84.5, 85.5, 86.5, 87.5, 88.5, 89.5, 90.5, 91.5, 93.0, 94.5, 95.5, 96.5, 97.5, 98.5, 99.5]
FINAL SPLIT:  41.5
education-num
16
=================================================================================
17
[0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5, 11.5, 12.5, 13.5, 14.5, 15.5, 16.5]
FINAL SPLIT:  12.5
PS C:\Users\Zahin\Documents\L-4 T-2\CSE 472 Machine Learning\Offline 1> & C:/Users/Zahin/Anaconda3/python.exe "c:/Users/Zahin/Documents/L-4 T-2/CSE 472 Machine Learning/Offline 1/DecisionTree.py"
-----------------DECISION TREE VERSION-----------------------
=====================TEST ACCURACYYYYY===================
16281
Total:  16281
Accuracy:  0.8250721700141269
True Positive:  2344
True Negative:  11089
False Positive:  1346
False Negative:  1502
Recall:  0.609464378575143
Specificity:  0.8917571371129875
Precision:  0.635230352303523
False Discovery Rate:  0.36476964769647696
F1 Score:  0.6220806794055201
=====================TRAIN ACCURACYYYYY===================
32561
Total:  32561
Accuracy:  0.9013850925954363
True Positive:  6066
True Negative:  23284
False Positive:  1436
False Negative:  1775
Recall:  0.7736258130340518
Specificity:  0.9419093851132686
Precision:  0.8085843774993335
False Discovery Rate:  0.1914156225006665
F1 Score:  0.7907188946099198
-----------------ADABOOST VERSION-----------------------
ROUND:  5
=============TRAIN ACCURACY=======================
5 5
32561
Total:  32561
Accuracy:  0.8194772887810571
True Positive:  3218
True Negative:  23465
False Positive:  1255
False Negative:  4623
=============TEST ACCURACY=======================
5 5
16281
Total:  16281
Accuracy:  0.8220625268718138
True Positive:  1573
True Negative:  11811
False Positive:  624
False Negative:  2273
ROUND:  10
=============TRAIN ACCURACY=======================
10 10
32561
Total:  32561
Accuracy:  0.8391941279444735
True Positive:  3761
True Negative:  23564
False Positive:  1156
False Negative:  4080
=============TEST ACCURACY=======================
10 10
16281
Total:  16281
Accuracy:  0.8408574411891161
True Positive:  1829
True Negative:  11861
False Positive:  574
False Negative:  2017
ROUND:  15
=============TRAIN ACCURACY=======================
15 15
32561
Total:  32561
Accuracy:  0.8406375725561255
True Positive:  3657
True Negative:  23715
False Positive:  1005
False Negative:  4184
=============TEST ACCURACY=======================
15 15
16281
Total:  16281
Accuracy:  0.8414716540753026
True Positive:  1767
True Negative:  11933
False Positive:  502
False Negative:  2079
ROUND:  20
=============TRAIN ACCURACY=======================
20 20
32561
Total:  32561
Accuracy:  0.843800866066767
True Positive:  4309
True Negative:  23166
False Positive:  1554
False Negative:  3532
=============TEST ACCURACY=======================
20 20
16281
Total:  16281
Accuracy:  0.8438056630428107
True Positive:  2077
True Negative:  11661
False Positive:  774
False Negative:  1769