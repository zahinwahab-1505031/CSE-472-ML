# -*- coding: utf-8 -*-
"""1505031_Code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EbvPkGuvwoIpkhYG2rRbAaqbPf0L6sYM
"""

from bs4 import BeautifulSoup as bs
import numpy as np
import string
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from nltk.stem import PorterStemmer
import re
import collections
import math
import sklearn

nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

from google.colab import drive
drive.mount('/content/drive')

topics = []
def getTopicnames():
    with open('/content/drive/My Drive/CSE_472_Assignment2_dataset/Data/topics_all.txt', 'r') as reader:
        line = reader.readline()
        while line != '':  # The EOF char is an empty string
            if line[-1] == "\n":

              topics.append(line[:-1])
            else:
              topics.append(line)
            line = reader.readline()



getTopicnames()
print(topics)

def preprocessText(raw_text):
    #remove html tags
    cleanr = re.compile('<.*?>')
    text = re.sub(cleanr, '', raw_text)
    #remove any URLs
    text = re.sub(r'(?:(?:http|https):\/\/)?([-a-zA-Z0-9.]{2,256}\.[a-z]{2,4})\b(?:\/[-a-zA-Z0-9@:%_\+.~#?&//=]*)?',"",text,flags=re.MULTILINE)
    text = re.sub(r"&nbsp;", " ", text)
   # text = re.sub(r'^http?:\/\/.*[\r\n]*', '', text, flags=re.MULTILINE)
    #text = re.sub(r'^https?:\/\/.*[\r\n]*', '', text, flags=re.MULTILINE)
    #text = re.sub(r'\s*(?:https?://)?www\.\S*\.[A-Za-z]{2,5}\s*', ' ', text).strip()
    #text = re.sub(r'\s*(?:http?://)?www\.\S*\.[A-Za-z]{2,5}\s*', ' ', text).strip()
    #Remove punctuations
    text=text.translate((str.maketrans('','',string.punctuation)))
    #Number Removal
    text = re.sub(r'[-+]?\d+', '', text)
    #removing unicode
    text = re.sub(r'[^\x00-\x7F]',' ', text) # 
    text = text.lower()
    #Tokenize
    text = word_tokenize(text)
    #Remove stopwords
    stop_words = set(stopwords.words('english'))
    text = [word for word in text if not word in stop_words]
    #Lemmatize tokens
    lemmatizer=WordNetLemmatizer()
    text = [lemmatizer.lemmatize(word) for word in text]
    #Stemming tokens
    stemmer= PorterStemmer()
    text = [stemmer.stem(word) for word in text]
    return text

X_train = []
Y_train = []
X_validation = []
Y_validation = []
X_test = []
Y_test = []
topic_dict = {}
topic_words_dict = {} # dict()
import random
prefix_for_colab = "/content/drive/My Drive/CSE_472_Assignment2_dataset/"
def preprocessData():
    list_of_words = []
    iter = 1
    count_train = 0
    for topic in topics:
        print(topic)
        list_of_words_in_topic = []
        topic_dict[iter] = topic
        topic_words_dict[iter] = []

        file_name = prefix_for_colab+"Data/Training/" + topic + ".xml"
        with open(file_name,'r',encoding='utf-8') as file:
                content = file.read()
                soup = bs(content)
                rows = soup.findAll("row")
                filled_rows = []
                for row in rows:
                  text = row["body"]
                  if text == '':
                    continue
                  else:
                    filled_rows.append(row)


                train_list_to_iterate = filled_rows[:500]
                validation_list_to_iterate = filled_rows[500:700]
                test_list_to_iterate = filled_rows[700:1200]
                for item in train_list_to_iterate:
                    text = item["body"]
                    processed_text = preprocessText(text)
                    X_train.append(np.array(processed_text))
                    Y_train.append(iter)
                    list_of_words.append(processed_text)
                    list_of_words_in_topic.append(processed_text)
                for item in validation_list_to_iterate:
                    text = item["body"]
                    processed_text = preprocessText(text)
                    X_validation.append(np.array(processed_text))
                    Y_validation.append(iter)
                for i in range(50):
                  temp_X = []
                  temp_Y = []
                  for item in test_list_to_iterate[i*10:(i+1)*10]:
                      text = item["body"]
                      processed_text = preprocessText(text)
                      if len(processed_text)==0:
                        continue
                      temp_X.append(np.array(processed_text))
                      temp_Y.append(iter)
                  
                  #print(temp_Y)
                  X_test.append(temp_X)
                  Y_test.append(temp_Y)
                  #print(Y_test)

        temp = sum(list_of_words_in_topic, []) 
        topic_words_dict[iter] = temp
        iter = iter + 1
    vocabulary_raw = sum(list_of_words, []) 
    return vocabulary_raw

      
vocabulary_raw = preprocessData()
print(topic_dict)
print(len(X_train))
print(len(X_validation))

def makeDictionary():
    import collections
    counts = collections.Counter(vocabulary_raw)
    return dict(counts)
feature_space = makeDictionary()
unique_words_in_feature_space = np.sort(np.array(list(feature_space.keys())).reshape(1,-1)[0])
print(len(unique_words_in_feature_space))
modV = len(unique_words_in_feature_space)
print(feature_space)
total_words = np.sum(np.array(list(feature_space.values())).reshape(1,-1)[0])
print(total_words)

Y_test_for_each_iteration = {}
for i in range(50):
  Y_test_for_each_iteration[i] = []
  temp = []
  for j in range(len(topics)):
    temp.append (Y_test[j*50:(j+1)*50][i])
  temp2 = sum(temp, []) 
  Y_test_for_each_iteration[i] = temp2
X_test_for_each_iteration = {}
for i in range(50):
  X_test_for_each_iteration[i] = []
  temp = []
  for j in range(len(topics)):
    temp.append (X_test[j*50:(j+1)*50][i])
  temp2 = sum(temp, []) 
  X_test_for_each_iteration[i] = temp2

def getNumericVector(string_tokens):
  numeric_vector = np.zeros((len(string_tokens),len(feature_space)))
  words_in_feature_space = np.sort(np.array(list(feature_space.keys())).reshape(1,-1)[0])
  for i in range(len(string_tokens)):
      arr1 = words_in_feature_space
      arr2 = np.array(string_tokens[i])
      temp = np.in1d(arr1,arr2)
      idx = np.searchsorted(arr1,arr2)
      idx[idx==len(arr1)] = 0
      mask = arr1[idx]==arr2
      out = np.bincount(idx[mask])
      temp = temp.astype('int64') # implicitly changes all the "False" values to 0
      np.putmask(temp, temp, out)
      numeric_vector[i] = temp
  return numeric_vector
X_test_numeric_vector_reprenstation = {}
for i in range(50):
  X_test_numeric_vector_reprenstation[i]=getNumericVector(X_test_for_each_iteration[i])

X_train_numeric_vector_reprenstation=getNumericVector(X_train)
X_validation_numeric_vector_reprenstation=getNumericVector(X_validation)   


X_test_boolean_vector_reprenstation = {}
for i in range(50):
  X_test_boolean_vector_reprenstation[i]=(X_test_numeric_vector_reprenstation[i] > 0).astype(int)

X_train_boolean_vector_reprenstation=(X_train_numeric_vector_reprenstation>0).astype(int)
X_validation_boolean_vector_reprenstation=(X_validation_numeric_vector_reprenstation>0).astype(int)

def getTFIDFVector(string_tokens,boolean_vector,numeric_vector,train_bool_vector,train_num_vector):
  #np.seterr(divide='ignore', invalid='ignore')
  tf_idf_vector = np.zeros((len(string_tokens),len(feature_space)))
  words_in_feature_space = np.sort(np.array(list(feature_space.keys())).reshape(1,-1)[0])
  D =   train_bool_vector.shape[0]
  C_w = np.sum(train_bool_vector,axis = 0).reshape(1,-1) #train
  alpha = 0.000000000000000001
  beta  = 0.000000000000000001
  idf = np.log( np.divide(D+alpha,C_w+beta))
  for i in range(len(string_tokens)):
      W_d = np.sum(numeric_vector[i]) #test
      if W_d == 0:
        W_d = 0.0000000000000000000000001
      tf = numeric_vector[i]/W_d  #test
      
      tf_idf_vector[i] = tf*idf
  return tf_idf_vector
X_test_TFIDF_vector_reprenstation = {}
for i in range(50):
  X_test_TFIDF_vector_reprenstation[i]=getTFIDFVector(X_test_for_each_iteration[i],X_test_boolean_vector_reprenstation[i],X_test_numeric_vector_reprenstation[i],X_train_boolean_vector_reprenstation,X_train_numeric_vector_reprenstation)

X_train_TFIDF_vector_reprenstation=getTFIDFVector(X_train,X_train_boolean_vector_reprenstation,X_train_numeric_vector_reprenstation,X_train_boolean_vector_reprenstation,X_train_numeric_vector_reprenstation)
X_validation_TFIDF_reprenstation=getTFIDFVector(X_validation,X_validation_boolean_vector_reprenstation,X_validation_numeric_vector_reprenstation,X_train_boolean_vector_reprenstation,X_train_numeric_vector_reprenstation)

def hamming_distance(instance1, instance2):
  dist = sklearn.metrics.pairwise.euclidean_distances(instance2, instance1)
  return np.square(dist)

def euclidean_distance(instance1, instance2):
  dist = sklearn.metrics.pairwise.euclidean_distances(instance2, instance1)

  return dist

def cosine_similarity(instance1, instance2):
  dist = sklearn.metrics.pairwise_distances(instance2,instance1, metric='cosine')
  return dist

def prediction_knn(X_train, Y_train, X_test, version, n_neighbors=3):
    Y_train = np.array(Y_train)
    
    #Determine Number of unique class lebels
    if version == 'v2':
      distances = euclidean_distance(X_train,X_test) #.reshape(1,-1)
    elif version == 'v1':
      distances = hamming_distance(X_train,X_test)#.reshape(1,-1)
    elif version == 'v3':
      distances = cosine_similarity(X_train,X_test)#.reshape(1,-1)
    Y_train_arr = np.array(Y_train.reshape(1,-1)[0])
    predOut = []
    small_num = 0.0000000000000000000000001
    for i in range(X_test.shape[0]):
        idx = np.argpartition(distances[i], n_neighbors)[:n_neighbors]
        sortedYtrain = Y_train_arr[idx]
        sortedDist = distances[i][idx]
        #(values,counts) = np.unique(sortedYtrain,return_counts=True)
        #ind=np.argmax(counts)
       # predOut.append(values[ind])
        voteCount = np.zeros(len(topics))
        for k in range(len(sortedYtrain)):
          if sortedDist[k] == 0:
           voteCount[sortedYtrain[k]-1] = voteCount[sortedYtrain[k]-1]+(1/small_num)
          else:
           voteCount[sortedYtrain[k]-1] = voteCount[sortedYtrain[k]-1]+(1/sortedDist[k])

        predOut.append(np.argmax(voteCount)+1)
    return predOut

def performanceEvaluation_knn(X_train, Y_train, X_test, Y_test, version, n_neighbors=3):
    print("K=",n_neighbors)
    totalCount = 0
    correctCount = 0
    predictedOutput = prediction_knn(X_train, Y_train, X_test,version, n_neighbors)
    comparison = np.equal(np.array(predictedOutput),np.array(Y_test)).astype('int64')
    correctCount = np.sum(comparison)
    totalCount = len(Y_test)
    print("Total Correct Count: ",correctCount," Total Wrong Count: ",totalCount-correctCount," Accuracy: ",(correctCount*100)/(totalCount))
    return (correctCount*100)/(totalCount)

print("=========================Hamming============================================================")
performanceEvaluation_knn(X_train_boolean_vector_reprenstation, Y_train, X_validation_boolean_vector_reprenstation, Y_validation,'v1',1)
performanceEvaluation_knn(X_train_boolean_vector_reprenstation, Y_train, X_validation_boolean_vector_reprenstation, Y_validation,'v1',3)
performanceEvaluation_knn(X_train_boolean_vector_reprenstation, Y_train, X_validation_boolean_vector_reprenstation, Y_validation,'v1',5)
print("=========================Euclidean============================================================")
performanceEvaluation_knn(X_train_numeric_vector_reprenstation, Y_train, X_validation_numeric_vector_reprenstation, Y_validation,'v2',1) 
performanceEvaluation_knn(X_train_numeric_vector_reprenstation, Y_train, X_validation_numeric_vector_reprenstation, Y_validation,'v2',3) 
performanceEvaluation_knn(X_train_numeric_vector_reprenstation, Y_train, X_validation_numeric_vector_reprenstation, Y_validation,'v2',5) 
print("=========================TF-IDF============================================================")
performanceEvaluation_knn(X_train_TFIDF_vector_reprenstation, Y_train, X_validation_TFIDF_reprenstation, Y_validation,'v3',1) 
performanceEvaluation_knn(X_train_TFIDF_vector_reprenstation, Y_train, X_validation_TFIDF_reprenstation, Y_validation,'v3',3) 
performanceEvaluation_knn(X_train_TFIDF_vector_reprenstation, Y_train, X_validation_TFIDF_reprenstation, Y_validation,'v3',5)

# Commented out IPython magic to ensure Python compatibility.
# %timeit
test_set_accuracy_knn = []
for i in range(50):
  print("==========================FOR ",i+1,"th iteration")
  test_set_accuracy_knn.append(performanceEvaluation_knn(X_train_TFIDF_vector_reprenstation, Y_train, X_test_TFIDF_vector_reprenstation[i], Y_test_for_each_iteration[i],'v3',5))

def prediction_Naive_Bayes(X_train, Y_train, X_test,alpha,unique_labels,P_cm_dt_arr,N_cm_arr,word_counts_in_this_topic_arr):
  #unique_labels, counts_labels = np.unique(Y_train, return_counts=True)
  predictedOutput = -1
  prob = -99999999999999
  for label in unique_labels:
    word_counts_in_this_topic = word_counts_in_this_topic_arr[label-1] 
    P_cm_dt =P_cm_dt_arr[label-1] 
    N_cm = N_cm_arr[label-1] 
    for word in X_test[0]:
      N_wj_cm = 0
      if word in word_counts_in_this_topic:
        N_wj_cm = word_counts_in_this_topic[word]
      P_wj_given_cm = (N_wj_cm + alpha) /(N_cm + alpha*modV)
      P_cm_dt = P_cm_dt+ math.log(P_wj_given_cm)
    if P_cm_dt > prob:
      prob = P_cm_dt
      predictedOutput = label

  return predictedOutput

unique_labels, counts_labels = np.unique(Y_train, return_counts=True)
P_cm_dt_arr = np.zeros(len(unique_labels))
N_cm_arr = np.zeros(len(unique_labels))
word_counts_in_this_topic_arr = []
for label in unique_labels:
  # print("For label: ",label)
  words_in_this_topic = topic_words_dict[label]
  counts = collections.Counter(words_in_this_topic)
  word_counts_in_this_topic_arr.append(dict(counts))
  P_cm_dt_arr[label-1] = math.log(counts_labels[label-1]/len(Y_train))
  N_cm_arr [label-1] = len(words_in_this_topic)

def performanceEvaluation_NB(X_train, Y_train, X_test, Y_test,alpha):
    print("Smoothing factor: ",alpha)
    
    totalCount = 0
    correctCount = 0
    for testInput, testActualOutput in zip(X_test, Y_test):
      predictedOutput = prediction_Naive_Bayes(X_train, Y_train, [testInput],alpha,unique_labels,P_cm_dt_arr,N_cm_arr,word_counts_in_this_topic_arr)
      
      if predictedOutput == testActualOutput:
            correctCount += 1
      totalCount += 1
    
    print("Total Correct Count: ",correctCount," Total Wrong Count: ",totalCount-correctCount," Accuracy: ",(correctCount*100)/(totalCount))
    return (correctCount*100)/(totalCount)

smoothing_factors = [0.0001,0.001,0.01,0.025,0.05,0.065,0.075,0.1,0.5,1,10,100]
for a in smoothing_factors:
   performanceEvaluation_NB(X_train, Y_train, X_validation, Y_validation,a)

print("=========================Naive Bayes============================================================")
test_set_accuracy_nb = []
for i in range(50):
  print("==========================FOR ",i+1,"th iteration")
  test_set_accuracy_nb.append(performanceEvaluation_NB(X_train, Y_train, X_test_for_each_iteration[i], Y_test_for_each_iteration[i],0.065))

print(test_set_accuracy_nb)
filename = "/content/drive/My Drive/CSE_472_Assignment2_dataset/Data/test_set_accuracy_nb.txt"
f=open(filename,'w')
for ele in test_set_accuracy_nb:
    f.write(str(ele)+'\n')

f.close()

print(test_set_accuracy_knn)
filename = "/content/drive/My Drive/CSE_472_Assignment2_dataset/Data/test_set_accuracy_knn.txt"
f=open(filename,'w')
for ele in test_set_accuracy_knn:
    f.write(str(ele)+'\n')

f.close()

test_set_accuracy_knn_arr = np.array(test_set_accuracy_knn)
print("Min: ",np.min(test_set_accuracy_knn_arr))
print("Max: ",np.max(test_set_accuracy_knn_arr))
print("Mean: ",np.mean(test_set_accuracy_knn_arr))
print("Std Dev: ",np.std(test_set_accuracy_knn_arr))

test_set_accuracy_nb_arr = np.array(test_set_accuracy_nb)
print("Min: ",np.min(test_set_accuracy_nb_arr))
print("Max: ",np.max(test_set_accuracy_nb_arr))
print("Mean: ",np.mean(test_set_accuracy_nb_arr))
print("Std Dev: ",np.std(test_set_accuracy_nb_arr))

from scipy import stats
ans = stats.ttest_rel(test_set_accuracy_knn,test_set_accuracy_nb)
print(ans)

