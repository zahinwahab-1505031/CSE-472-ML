{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 100)\n",
      "(1000, 100)\n",
      "Covariance matrix \n",
      "[[ 1.001001   -0.52321505  0.94317205 ...  0.94265375  0.94237121\n",
      "   0.94288611]\n",
      " [-0.52321505  1.001001   -0.20759705 ... -0.20788077 -0.20558825\n",
      "  -0.20688258]\n",
      " [ 0.94317205 -0.20759705  1.001001   ...  1.00010242  1.00067435\n",
      "   1.00074872]\n",
      " ...\n",
      " [ 0.94265375 -0.20788077  1.00010242 ...  1.001001    0.9999984\n",
      "   1.00001326]\n",
      " [ 0.94237121 -0.20558825  1.00067435 ...  0.9999984   1.001001\n",
      "   1.00064307]\n",
      " [ 0.94288611 -0.20688258  1.00074872 ...  1.00001326  1.00064307\n",
      "   1.001001  ]]\n",
      "Eigenvectors \n",
      "[[-9.53050756e-02  3.19221524e-01  8.97450276e-03 ...  2.36325419e-02\n",
      "   6.52363899e-03 -1.30777256e-04]\n",
      " [ 2.14520537e-02 -9.46130534e-01 -1.23280120e-03 ...  7.47576184e-03\n",
      "   1.79442749e-03  8.38941041e-04]\n",
      " [-1.00942667e-01 -4.99549304e-03  8.09260067e-03 ...  3.76810482e-02\n",
      "   6.46600229e-03  3.30571333e-02]\n",
      " ...\n",
      " [-1.00873233e-01 -4.57243061e-03  8.91669044e-03 ... -9.49146544e-03\n",
      "   4.62063223e-03  5.81292279e-03]\n",
      " [-1.00929380e-01 -6.95935547e-03  9.06893095e-03 ... -1.77141390e-01\n",
      "   2.18354285e-01 -3.09653761e-01]\n",
      " [-1.00936836e-01 -5.68865252e-03  9.73198145e-03 ...  9.69325765e-02\n",
      "  -3.56186938e-02 -3.55035666e-03]]\n",
      "\n",
      "Eigenvalues \n",
      "[9.82097532e+01 1.06771440e+00 1.45981351e-01 1.31446876e-01\n",
      " 9.97204892e-02 8.39609447e-02 7.61364857e-02 3.04088389e-02\n",
      " 2.89953555e-02 2.43844561e-02 2.30484567e-02 1.88671975e-02\n",
      " 1.52241781e-02 1.39138930e-02 1.15886700e-02 1.03598445e-02\n",
      " 5.85579632e-03 5.37580096e-03 5.10175490e-03 5.02731174e-03\n",
      " 4.72063759e-03 4.59795364e-03 3.99263845e-03 3.87885527e-03\n",
      " 3.34721275e-03 3.21540469e-03 2.99021223e-03 2.84705497e-03\n",
      " 2.76101969e-03 2.42488600e-03 2.18394924e-03 2.09643423e-03\n",
      " 2.01989972e-03 1.88462155e-03 1.71941044e-03 1.66423159e-03\n",
      " 1.63350250e-03 1.53246086e-03 1.46154068e-03 1.43157551e-03\n",
      " 1.33353999e-03 1.30001101e-03 1.27150944e-03 1.21176288e-03\n",
      " 1.20005849e-03 1.15620631e-03 1.13354093e-03 1.09154209e-03\n",
      " 1.01587348e-03 1.06461291e-03 1.05638873e-03 9.47707904e-04\n",
      " 9.89821731e-04 9.38024484e-04 9.86945818e-05 8.72687645e-04\n",
      " 8.47523712e-04 7.67438595e-04 7.54141943e-04 7.08743025e-04\n",
      " 7.11034215e-04 1.64057791e-04 6.51508913e-04 6.19929626e-04\n",
      " 1.74468883e-04 1.80249365e-04 5.94243863e-04 5.89303301e-04\n",
      " 1.86720466e-04 1.96752434e-04 5.60714891e-04 2.12870587e-04\n",
      " 2.15652352e-04 2.22528531e-04 5.43681847e-04 2.33347924e-04\n",
      " 5.17621335e-04 5.38916312e-04 2.44029564e-04 2.55904621e-04\n",
      " 2.62603328e-04 4.85444520e-04 4.66878881e-04 3.13072008e-04\n",
      " 2.85311672e-04 2.99435454e-04 4.56985606e-04 2.71794219e-04\n",
      " 3.38584062e-04 3.64537250e-04 3.83877702e-04 4.52135031e-04\n",
      " 4.36023880e-04 2.94037067e-04 3.33809655e-04 4.00332263e-04\n",
      " 4.26982246e-04 3.73097764e-04 4.04944925e-04 4.08080218e-04]\n",
      "Eigenvalues in descending order:\n",
      "98.20975315996711\n",
      "1.0677144032146537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization\n",
      "Means:\n",
      " [[-4.26209577  0.02871596]\n",
      " [ 7.80382482  2.04719386]\n",
      " [-6.31811969  0.50086761]]\n",
      "Co-variances:\n",
      " [[[ 1.16393397e+02 -1.22512675e-01]\n",
      "  [-1.22512675e-01  1.06853983e+00]]\n",
      "\n",
      " [[ 1.59170396e+02  1.59919342e+01]\n",
      "  [ 1.59919342e+01  5.26291230e+00]]\n",
      "\n",
      " [[ 1.38168348e+02 -3.16770918e+00]\n",
      "  [-3.16770918e+00  1.31883388e+00]]]\n",
      "weights:\n",
      " [0.33 0.33 0.34]\n",
      "-5421.70202509679\n",
      "Before starting EM algo: 5421.70202509679\n",
      "==================Iteration: 1 =========================\n",
      "Loglikelihood: 5118.699034138392\n",
      "==================Iteration: 2 =========================\n",
      "Loglikelihood: 5072.827064826036\n",
      "==================Iteration: 3 =========================\n",
      "Loglikelihood: 5005.144752758481\n",
      "==================Iteration: 4 =========================\n",
      "Loglikelihood: 4936.832053204694\n",
      "==================Iteration: 5 =========================\n",
      "Loglikelihood: 4885.6154385174\n",
      "==================Iteration: 6 =========================\n",
      "Loglikelihood: 4859.902991859009\n",
      "==================Iteration: 7 =========================\n",
      "Loglikelihood: 4842.205693550504\n",
      "==================Iteration: 8 =========================\n",
      "Loglikelihood: 4817.45950367218\n",
      "==================Iteration: 9 =========================\n",
      "Loglikelihood: 4775.550701987683\n",
      "==================Iteration: 10 =========================\n",
      "Loglikelihood: 4728.3049434482455\n",
      "==================Iteration: 11 =========================\n",
      "Loglikelihood: 4698.494150013209\n",
      "==================Iteration: 12 =========================\n",
      "Loglikelihood: 4676.5388211184045\n",
      "==================Iteration: 13 =========================\n",
      "Loglikelihood: 4655.434081783866\n",
      "==================Iteration: 14 =========================\n",
      "Loglikelihood: 4634.6845044640495\n",
      "==================Iteration: 15 =========================\n",
      "Loglikelihood: 4617.401948380612\n",
      "==================Iteration: 16 =========================\n",
      "Loglikelihood: 4606.55443548278\n",
      "==================Iteration: 17 =========================\n",
      "Loglikelihood: 4601.034469491993\n",
      "==================Iteration: 18 =========================\n",
      "Loglikelihood: 4598.494578682396\n",
      "==================Iteration: 19 =========================\n",
      "Loglikelihood: 4597.398232418317\n",
      "==================Iteration: 20 =========================\n",
      "Loglikelihood: 4596.954422226204\n",
      "==================Iteration: 21 =========================\n",
      "Loglikelihood: 4596.785078568973\n",
      "==================Iteration: 22 =========================\n",
      "Loglikelihood: 4596.723118038855\n",
      "==================Iteration: 23 =========================\n",
      "Loglikelihood: 4596.701012042605\n",
      "==================Iteration: 24 =========================\n",
      "Loglikelihood: 4596.693234337545\n",
      "==================Iteration: 25 =========================\n",
      "Loglikelihood: 4596.690517625408\n",
      "==================Iteration: 26 =========================\n",
      "Loglikelihood: 4596.689571933802\n",
      "==================Iteration: 27 =========================\n",
      "Loglikelihood: 4596.689243147761\n",
      "==================Iteration: 28 =========================\n",
      "Loglikelihood: 4596.689128842114\n",
      "==================Iteration: 29 =========================\n",
      "Loglikelihood: 4596.689089076391\n",
      "==================Iteration: 30 =========================\n",
      "Loglikelihood: 4596.689075228065\n",
      "==================Iteration: 31 =========================\n",
      "Loglikelihood: 4596.689070399547\n",
      "==================Iteration: 32 =========================\n",
      "Loglikelihood: 4596.689068713795\n",
      "==================Iteration: 33 =========================\n",
      "Loglikelihood: 4596.689068124482\n",
      "Final:\n",
      "Means:\n",
      " [[ -0.65490696  -0.91103357]\n",
      " [ 14.23271415   0.67616318]\n",
      " [-10.41170435   0.8563192 ]]\n",
      "Co-variances:\n",
      " [[[22.04644472  0.83026857]\n",
      "  [ 0.83026857  0.26001577]]\n",
      "\n",
      " [[ 6.92272453 -0.47558014]\n",
      "  [-0.47558014  0.66884288]]\n",
      "\n",
      " [[16.4855099  -0.61339994]\n",
      "  [-0.61339994  0.24986888]]]\n",
      "weights:\n",
      " [0.46002022 0.24035382 0.29962595]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "with open('data.txt') as file:\n",
    "    data = np.array([np.array([float(digit) for digit in line.split()]) for line in file])\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_std = StandardScaler().fit_transform(data)\n",
    "#print(X_train)\n",
    "#print(X_std)\n",
    "print(X_std.shape)\n",
    "mean_vec = np.mean(X_std, axis=0)\n",
    "cov_mat =( (X_std - mean_vec).T.dot((X_std - mean_vec)) )/ (X_std.shape[0]-1)\n",
    "print('Covariance matrix \\n%s' %cov_mat)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "\n",
    "print('Eigenvectors \\n%s' %eig_vecs)\n",
    "print('\\nEigenvalues \\n%s' %eig_vals)\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "# Make a list of (eigenvalue, eigenvector) tuples\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# Visually confirm that the list is correctly sorted by decreasing eigenvalues\n",
    "print('Eigenvalues in descending order:')\n",
    "k = 0\n",
    "eig_vec_top_2 = np.zeros((2,data.shape[1]))\n",
    "for i in eig_pairs[:2]:\n",
    "    print(i[0])\n",
    "    eig_vec_top_2 [k] = i[1]\n",
    "    k = k+1\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "projection_matrix = (eig_vec_top_2.T[:][:]).T\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "X_pca = X_std.dot(projection_matrix.T)\n",
    "X_pca\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "plt.scatter(X_pca.T[0],X_pca.T[1])\n",
    "\n",
    "plt.savefig('pcaplot.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "\n",
    "K = 3\n",
    "D = 2\n",
    "np.random.seed(42)\n",
    "\n",
    "means = np.zeros((K,D))\n",
    "covariances = np.zeros((K,D,D))\n",
    "#covariances =np.random.randn(K,D,D)\n",
    "weights =np.array([0.33,0.33,0.34])\n",
    "\n",
    "from numpy import random\n",
    "\n",
    "\n",
    "for k in range(K):\n",
    "    x = random.randint(1000)\n",
    "    means[k] = X_pca[x]\n",
    "\n",
    "for k in range(K):\n",
    "    x = random.randint(1000)\n",
    "    \n",
    "    covariances[k]=( (X_pca - means[k]).T.dot((X_pca - means[k])) )/ (X_pca.shape[0]-1)\n",
    "print(\"Initialization\")\n",
    "print(\"Means:\\n\",means)\n",
    "print(\"Co-variances:\\n\",covariances)\n",
    "print(\"weights:\\n\",weights)\n",
    "Nk_xi_arr = np.zeros((data.shape[0],K))\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    for k in range(K):\n",
    "        \n",
    "        temp2 = math.sqrt(pow(2*3.1416,D)*abs(np.linalg.det(covariances[k]) ))\n",
    "        x_i = X_pca[i]\n",
    "        temp3 = np.linalg.inv(covariances[k])\n",
    "        row = (x_i - means[k]).reshape(-1,1)\n",
    "        temp = np.matmul(row.T,(np.matmul(temp3,row)))\n",
    "        Nk_xi_arr[i][k]=(1/temp2)*np.exp(-0.5*temp)\n",
    "\n",
    "\n",
    "\n",
    "loglikelihood = 0\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    sum = 0\n",
    "    for k in range(K):\n",
    "        sum = sum + weights[k]*Nk_xi_arr[i,k]\n",
    "    loglikelihood = loglikelihood + math.log(sum)\n",
    "print(loglikelihood)\n",
    "loglikelihood = abs(loglikelihood)\n",
    "def EM_Algorithm(means,covariances,weights,loglikelihood,Nk_xi_arr,K,D):\n",
    "   # print(\"In EM algo function:=============================\")\n",
    "    #print(\"Means:\\n\",means)\n",
    "    #print(\"Co-variances:\\n\",covariances)\n",
    "    #print(\"weights:\\n\",weights)\n",
    "    print(\"Before starting EM algo:\",loglikelihood)\n",
    "    iteration = 1\n",
    "    while(True):\n",
    "        print(\"==================Iteration:\",iteration,\"=========================\")\n",
    "        iteration = iteration + 1\n",
    "        \n",
    "        P_ik_arr = np.zeros((data.shape[0],K))\n",
    "       # print(P_ik_arr)\n",
    "        for i in range(data.shape[0]):\n",
    "           # denom = np.sum(np.multiply(weights.reshape(1,-1),Nk_xi_arr[i].reshape(1,-1)))\n",
    "            denominator = 0\n",
    "            for k in range(K):\n",
    "                denominator =  denominator + (Nk_xi_arr[i][k]*weights[k])\n",
    "            for k in range(K):\n",
    "                P_ik_arr[i][k] = (Nk_xi_arr[i][k]*weights[k]) / denominator\n",
    "        \n",
    "       # print(P_ik_arr)\n",
    "       # print(\"checking mean\")\n",
    "        for k in range(K):\n",
    "          #  print(P_ik_arr[:,k].reshape(-1,1)[0])\n",
    "          #  print(X_pca[0])\n",
    "          #  print(np.multiply(P_ik_arr[:,k].reshape(-1,1),X_pca)[0])\n",
    "            numerator = np.sum(np.multiply(P_ik_arr[:,k].reshape(-1,1),X_pca),axis=0)\n",
    "            denominator = np.sum(P_ik_arr[:,k].reshape(-1,1))\n",
    "            means[k] = numerator/denominator\n",
    "        for k in range(K):\n",
    "            numerator = np.zeros((D,D))\n",
    "            for i in range(data.shape[0]):\n",
    "                row = X_pca[i]  - means[k]\n",
    "                temp = (row.reshape(-1,1))\n",
    "                temp2 = (row.reshape(1,-1))\n",
    "                #print(\"covar calc:\",temp,\"*\",temp2,\"=\",np.matmul(temp,temp2))\n",
    "                numerator = numerator + P_ik_arr[i,k]*(np.matmul(temp,temp2))\n",
    "\n",
    "            denominator = np.sum(P_ik_arr[:,k].reshape(-1,1))\n",
    "            covariances[k] = numerator/denominator\n",
    "        N = data.shape[0]\n",
    "        for k in range(K):\n",
    "            numerator = np.sum(P_ik_arr[:,k].reshape(-1,1))\n",
    "            weights[k] = numerator/N\n",
    "      #  print(\"Means:\\n\",means)\n",
    "       # print(\"Co-variances:\\n\",covariances)\n",
    "        #print(\"weights:\\n\",np.sum(weights))\n",
    "        Nk_xi_arr = np.zeros((data.shape[0],K))\n",
    "        for i in range(data.shape[0]):\n",
    "            for k in range(K):\n",
    "                temp2 = math.sqrt(pow(2*3.1416,D)*abs(np.linalg.det(covariances[k]) ))\n",
    "\n",
    "                x_i = X_pca[i]\n",
    "                temp3 = np.linalg.inv(covariances[k])\n",
    "                row = (x_i - means[k]).reshape(-1,1)\n",
    "                \n",
    "                temp = np.matmul(row.T,(np.matmul(temp3,row)))\n",
    "                Nk_xi_arr[i][k]=(1/temp2)*np.exp(-0.5*temp)\n",
    "        previous_loglikelihood = loglikelihood\n",
    "        loglikelihood = 0\n",
    "\n",
    "        for i in range(data.shape[0]):\n",
    "            sum = 0\n",
    "            for k in range(K):\n",
    "                sum = sum + weights[k]*Nk_xi_arr[i,k]\n",
    "            loglikelihood = loglikelihood + math.log(sum)\n",
    "        \n",
    "        loglikelihood = abs(loglikelihood)\n",
    "        print(\"Loglikelihood:\",loglikelihood)\n",
    "        diff = loglikelihood - previous_loglikelihood\n",
    "      #  print(\"difference: \",diff)\n",
    "        #if iteration == 10:\n",
    "        if abs(diff) <= pow(10,-6):\n",
    "            print(\"Final:\")\n",
    "            print(\"Means:\\n\",means)\n",
    "            print(\"Co-variances:\\n\",covariances)\n",
    "            print(\"weights:\\n\",weights)\n",
    "            break\n",
    "   # print(P_ik_arr)\n",
    "    return P_ik_arr\n",
    "        \n",
    "    \n",
    "Final_Probability = EM_Algorithm(means,covariances,weights,loglikelihood,Nk_xi_arr,K,D)    \n",
    "from scipy.special import softmax\n",
    "softmax_arr = softmax(Final_Probability, axis=1)\n",
    "boolean_arr = np.zeros_like(softmax_arr)\n",
    "boolean_arr[np.arange(len(softmax_arr)), softmax_arr.argmax(1)] = 1\n",
    "color = []\n",
    "for i in range(data.shape[0]):\n",
    "    idx = np.where(boolean_arr[i]==1)[0][0]\n",
    "    if idx == 0:\n",
    "        color.append( 'green')\n",
    "    elif idx == 1:\n",
    "        \n",
    "        color.append('red')\n",
    "    elif idx == 2:\n",
    "        color.append('blue')\n",
    "  \n",
    "plt.scatter(X_pca.T[0],X_pca.T[1],c=color)\n",
    "plt.savefig('em_pca.png')\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "\n",
    "  # plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
